name: Stock Data Pipeline

on:
  schedule:
    # 每天北京时间上午9点运行 (UTC+8的0点)
    - cron: '0 16 * * *'
  workflow_dispatch:  # 允许手动触发

jobs:
  scrape-and-upload:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install DrissionPage==1.0.0 seatable-api==1.0.0

    - name: Run stock data pipeline
      env:
        SEATABLE_API_TOKEN: ${{ secrets.SEATABLE_API_TOKEN }}
      run: python main.py  # 替换为实际脚本文件名

    - name: Archive logs (optional)
      if: always()  # 无论成功失败都执行
      uses: actions/upload-artifact@v3
      with:
        name: execution-logs
        path: |
          *.log
          *.txt
